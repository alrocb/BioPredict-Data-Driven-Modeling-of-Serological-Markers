Analysis started at 2025-03-24 12:28:20
================================================================================
C:\Users\Alex\Desktop\GRIFOLS\TFG\CÃ³digo\BioPredict
Starting Data Merging Process
Data Merging Completed.
Starting Data Cleaning Process
Data Cleaning Completed.
Starting Data Loading and Preprocessing for Analysis
Dataset Info:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7656 entries, 0 to 7655
Columns: 1275 entries, SEQN to WHQ520
dtypes: float64(1249), int64(26)
memory usage: 74.5 MB

Percentage of Missing Values:
SEQN         0.000000
RIAGENDR     0.000000
RIDAGEYR     0.000000
RIDRETH1     0.000000
RIDRETH3     0.000000
              ...    
WHD140      26.214734
WHQ150      27.194357
WHQ030M     83.228840
WHQ500      83.228840
WHQ520      83.228840
Length: 1275, dtype: float64
Correlation heatmap saved as outputs\plots\correlation_heatmap.png
                    Description             Value
0                    Session id               123
1                        Target             HBsAg
2                   Target type            Binary
3                Target mapping    1.0: 0, 2.0: 1
4           Original data shape        (7656, 19)
5        Transformed data shape        (7656, 19)
6   Transformed train set shape        (5359, 19)
7    Transformed test set shape        (2297, 19)
8              Numeric features                18
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              953b
                                    Model  Accuracy     AUC  Recall   Prec.  \
gbc          Gradient Boosting Classifier    0.7451  0.7530  0.7451  0.7248   
rf               Random Forest Classifier    0.7363  0.7433  0.7363  0.7158   
lightgbm  Light Gradient Boosting Machine    0.7356  0.7458  0.7356  0.7156   
ada                  Ada Boost Classifier    0.7315  0.7243  0.7315  0.7058   
et                 Extra Trees Classifier    0.7279  0.7312  0.7279  0.7038   
lr                    Logistic Regression    0.7147  0.6841  0.7147  0.6742   
lda          Linear Discriminant Analysis    0.7128  0.6842  0.7128  0.6702   
ridge                    Ridge Classifier    0.7126  0.6843  0.7126  0.6692   
dummy                    Dummy Classifier    0.7085  0.5000  0.7085  0.5020   
knn                K Neighbors Classifier    0.7063  0.6438  0.7063  0.6807   
svm                   SVM - Linear Kernel    0.6753  0.6533  0.6753  0.6315   
dt               Decision Tree Classifier    0.6518  0.5828  0.6518  0.6550   
qda       Quadratic Discriminant Analysis    0.4648  0.5698  0.4648  0.6712   
nb                            Naive Bayes    0.4118  0.6325  0.4118  0.6655   

              F1   Kappa     MCC  TT (Sec)  
gbc       0.7195  0.2905  0.3114     0.169  
rf        0.7166  0.2868  0.2990     0.159  
lightgbm  0.7173  0.2894  0.3001     0.116  
ada       0.7004  0.2409  0.2632     0.068  
et        0.7038  0.2528  0.2673     0.151  
lr        0.6495  0.1165  0.1567     0.596  
lda       0.6480  0.1125  0.1504     0.012  
ridge     0.6276  0.0718  0.1191     0.012  
dummy     0.5877  0.0000  0.0000     0.012  
knn       0.6861  0.2109  0.2187     0.025  
svm       0.6000  0.0583  0.0811     0.023  
dt        0.6532  0.1644  0.1646     0.017  
qda       0.4332  0.0814  0.1305     0.020  
nb        0.3726  0.0705  0.1173     0.012  
Model Comparison Results:
                                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC  TT (Sec)
gbc          Gradient Boosting Classifier    0.7451  0.7530  0.7451  0.7248  0.7195  0.2905  0.3114     0.169
rf               Random Forest Classifier    0.7363  0.7433  0.7363  0.7158  0.7166  0.2868  0.2990     0.159
lightgbm  Light Gradient Boosting Machine    0.7356  0.7458  0.7356  0.7156  0.7173  0.2894  0.3001     0.116
ada                  Ada Boost Classifier    0.7315  0.7243  0.7315  0.7058  0.7004  0.2409  0.2632     0.068
et                 Extra Trees Classifier    0.7279  0.7312  0.7279  0.7038  0.7038  0.2528  0.2673     0.151
lr                    Logistic Regression    0.7147  0.6841  0.7147  0.6742  0.6495  0.1165  0.1567     0.596
lda          Linear Discriminant Analysis    0.7128  0.6842  0.7128  0.6702  0.6480  0.1125  0.1504     0.012
ridge                    Ridge Classifier    0.7126  0.6843  0.7126  0.6692  0.6276  0.0718  0.1191     0.012
dummy                    Dummy Classifier    0.7085  0.5000  0.7085  0.5020  0.5877  0.0000  0.0000     0.012
knn                K Neighbors Classifier    0.7063  0.6438  0.7063  0.6807  0.6861  0.2109  0.2187     0.025
svm                   SVM - Linear Kernel    0.6753  0.6533  0.6753  0.6315  0.6000  0.0583  0.0811     0.023
dt               Decision Tree Classifier    0.6518  0.5828  0.6518  0.6550  0.6532  0.1644  0.1646     0.017
qda       Quadratic Discriminant Analysis    0.4648  0.5698  0.4648  0.6712  0.4332  0.0814  0.1305     0.020
nb                            Naive Bayes    0.4118  0.6325  0.4118  0.6655  0.3726  0.0705  0.1173     0.012
Auc plot saved
Confusion_matrix plot saved
Learning plot saved
Calibration plot saved
Pr plot saved
Feature importance plot saved
                          Model  Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC
0  Gradient Boosting Classifier    0.7214  0.7433  0.7214  0.6911  0.6875  0.2082  0.2292
Predictions saved to outputs\test_predictions.csv
Predictions (first 5 rows):
      Country_of_Birth  Income_to_Poverty_Ratio  Gender  Age  ...  Waist_Circumference  HBsAg  prediction_label  prediction_score
894                  1                     5.00       2   12  ...            66.199997    2.0                 2            0.7004
1192                 1                     5.00       2   64  ...           126.199997    2.0                 2            0.9546
411                  2                     1.29       2   28  ...            86.300003    1.0                 1            0.5439
1132                 2                     1.81       1   44  ...            92.900002    2.0                 2            0.8650
6625                 1                     1.20       2   44  ...           111.099998    2.0                 2            0.9305

[5 rows x 21 columns]
Classification Report:
              precision    recall  f1-score   support

         1.0       0.55      0.27      0.36       670
         2.0       0.75      0.91      0.82      1627

    accuracy                           0.72      2297
   macro avg       0.65      0.59      0.59      2297
weighted avg       0.69      0.72      0.69      2297

Shap interpretation plot could not be generated: This function only supports tree based models for binary classification: dt, et, lightgbm, rf.
      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC
Fold                                                          
0       0.7090  0.7085  0.7090  0.6765  0.6783  0.1884  0.2032
1       0.7537  0.7829  0.7537  0.7371  0.7256  0.3073  0.3351
2       0.7332  0.7781  0.7332  0.7092  0.7075  0.2598  0.2770
3       0.7481  0.7601  0.7481  0.7285  0.7218  0.2951  0.3178
4       0.7500  0.7484  0.7500  0.7310  0.7254  0.3049  0.3258
5       0.7556  0.7530  0.7556  0.7392  0.7268  0.3069  0.3361
6       0.7463  0.7211  0.7463  0.7260  0.7203  0.2914  0.3130
7       0.7556  0.7602  0.7556  0.7383  0.7321  0.3219  0.3432
8       0.7407  0.7527  0.7407  0.7192  0.7168  0.2836  0.3010
9       0.7589  0.7645  0.7589  0.7429  0.7404  0.3461  0.3615
Mean    0.7451  0.7530  0.7451  0.7248  0.7195  0.2905  0.3114
Std     0.0141  0.0219  0.0141  0.0188  0.0160  0.0403  0.0424
Fitting 10 folds for each of 10 candidates, totalling 100 fits
Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC
Fold                                                          
0       0.7183  0.7073  0.7183  0.6835  0.6611  0.1463  0.1858
1       0.7183  0.7905  0.7183  0.6864  0.6472  0.1174  0.1689
2       0.7183  0.7812  0.7183  0.6817  0.6546  0.1278  0.1710
3       0.7444  0.7613  0.7444  0.7415  0.6866  0.2087  0.2792
4       0.7369  0.7600  0.7369  0.7264  0.6756  0.1817  0.2475
5       0.7313  0.7590  0.7313  0.7180  0.6637  0.1540  0.2208
6       0.7369  0.7293  0.7369  0.7264  0.6756  0.1817  0.2475
7       0.7295  0.7578  0.7295  0.7073  0.6683  0.1625  0.2174
8       0.7388  0.7577  0.7388  0.7277  0.6806  0.1933  0.2564
9       0.7402  0.7615  0.7402  0.7286  0.6850  0.2046  0.2649
Mean    0.7313  0.7566  0.7313  0.7128  0.6698  0.1678  0.2259
Std     0.0094  0.0223  0.0094  0.0206  0.0125  0.0298  0.0377
      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC
Fold                                                          
0       0.7183  0.7136  0.7183  0.6868  0.6829  0.1988  0.2202
1       0.7575  0.7883  0.7575  0.7431  0.7276  0.3118  0.3442
2       0.7239  0.7801  0.7239  0.6958  0.6944  0.2256  0.2435
3       0.7444  0.7629  0.7444  0.7236  0.7188  0.2878  0.3083
4       0.7649  0.7535  0.7649  0.7516  0.7388  0.3378  0.3666
5       0.7444  0.7533  0.7444  0.7239  0.7107  0.2654  0.2964
6       0.7276  0.7176  0.7276  0.6998  0.6949  0.2259  0.2481
7       0.7575  0.7676  0.7575  0.7413  0.7305  0.3168  0.3438
8       0.7407  0.7579  0.7407  0.7182  0.7089  0.2613  0.2879
9       0.7589  0.7709  0.7589  0.7431  0.7337  0.3261  0.3512
Mean    0.7438  0.7565  0.7438  0.7227  0.7141  0.2757  0.3010
Std     0.0154  0.0231  0.0154  0.0214  0.0180  0.0455  0.0484
Transformation Pipeline and Model Successfully Saved
Best model saved to outputs\models\best_model_pipeline
Transformation Pipeline and Model Successfully Saved
Refined model saved to outputs\models\refined_model_pipeline
Error getting feature importance: 'ClassificationExperiment' object has no attribute 'get_feature_importance'
Trying alternative approach using model's feature_importances_...

Alternative Feature Importance:
                        Feature     Value
3                           Age  0.332355
11        HepatitisB_Vaccinated  0.153783
9                Race_Ethnicity  0.115653
17          Waist_Circumference  0.090290
5               Education_Level  0.053900
16              Body_Mass_Index  0.053329
0              Country_of_Birth  0.049809
1       Income_to_Poverty_Ratio  0.036991
6                Marital_Status  0.034145
12        Alcohol_Frequency_12m  0.018163
4   Household_Reference_Country  0.017106
8                 Family_Income  0.010924
14          Unprotected_Sex_12m  0.009742
7                Household_Size  0.009683
2                        Gender  0.007784
10          Injected_Drugs_Ever  0.005758
15            Private_Insurance  0.000584
13               Dental_Implant  0.000000
Alternative feature importance saved to outputs\feature_importance_alt.csv
Alternative feature importance plot saved to outputs\plots\alt_feature_importance.png
Moved AUC.png to outputs\plots
Moved Calibration Curve.png to outputs\plots
Moved Confusion Matrix.png to outputs\plots
Moved Feature Importance.png to outputs\plots
Moved Learning Curve.png to outputs\plots
Moved Precision Recall.png to outputs\plots
================================================================================
Analysis completed successfully at 2025-03-24 12:30:02
Results saved in outputs
